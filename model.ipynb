{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-unprocessed.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwL-botFUXmR"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import shutil\n",
        "import os\n",
        "import seaborn as sns\n",
        "\n",
        "from keras import layers\n",
        "from tensorflow.keras import applications \n",
        "from keras.applications import MobileNetV2\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "from scipy import interp\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTaeprh3UipD"
      },
      "source": [
        "!kaggle --version #make sure it's 1.5.8 if data is downloaded strangely"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfiYCekVdco"
      },
      "source": [
        "!kaggle competitions download -c aptos2019-blindness-detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AOp59U0UdTW"
      },
      "source": [
        "train_df = pd.read_csv('train_data.csv')\n",
        "val_df = pd.read_csv('val_data.csv')\n",
        "print(train_df.shape)\n",
        "print(val_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOLJrUSkUiTS"
      },
      "source": [
        "train_df['diagnosis'].value_counts()\n",
        "train_df['diagnosis'].hist()\n",
        "print(train_df.head())\n",
        "print(train_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-kNqEbeVkzy"
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "X = train_df\n",
        "normal = X[X.diagnosis==0]\n",
        "mild = X[X.diagnosis==1]\n",
        "moderate = X[X.diagnosis==2]\n",
        "severe = X[X.diagnosis==3]\n",
        "pdr = X[X.diagnosis==4]\n",
        "\n",
        "normal = resample(normal,\n",
        "                  replace=False,\n",
        "                  n_samples=700,\n",
        "                  random_state=2)\n",
        "mild = resample(mild,\n",
        "                replace=True, \n",
        "                n_samples=700,\n",
        "                random_state=2)\n",
        "moderate = resample(moderate,\n",
        "                    replace=False,\n",
        "                    n_samples=700,\n",
        "                    random_state=2)\n",
        "severe = resample(severe,\n",
        "                  replace=True,\n",
        "                  n_samples=700,\n",
        "                  random_state=2)\n",
        "pdr = resample(pdr,\n",
        "               replace=True,\n",
        "               n_samples=700,\n",
        "               random_state=2)\n",
        "\n",
        "# combine\n",
        "sampled = pd.concat([normal, mild, moderate, severe, pdr])\n",
        "\n",
        "sampled_train_df = sampled\n",
        "sampled_train_df = sampled_train_df.sample(frac=1).reset_index(drop=True)\n",
        "print(sampled_train_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLasz6hIVm3c"
      },
      "source": [
        "PATH_TO_DATA = '' # Put the path to the Aptos 2019 Kaggle data containing all the images here \n",
        "\n",
        "def resize_image(image):\n",
        "  return cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "# Normalize to range [0, 1]\n",
        "def normalize_image(image):\n",
        "  image = resize_image(image)\n",
        "  return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
        "\n",
        "x_train = np.empty((sampled_train_df.shape[0], 224, 224 ,3), dtype=np.float32)\n",
        "for idx, image_path in enumerate(tqdm(sampled_train_df['id_code'])):\n",
        "  image = normalize_image(cv2.cvtColor(cv2.imread(f'{PATH_TO_DATA}/{image_path}.png'), cv2.COLOR_BGR2RGB))\n",
        "  x_train[idx, :, :, :] = image\n",
        "\n",
        "x_val = np.empty((val_df.shape[0], 224, 224 ,3), dtype=np.float32)\n",
        "for idx, image_path in enumerate(tqdm(val_df['id_code'])):\n",
        "  image = normalize_image(cv2.cvtColor(cv2.imread(f'{PATH_TO_DATA}/{image_path}.png'), cv2.COLOR_BGR2RGB))\n",
        "  x_val[idx, :, :, :] = image\n",
        "\n",
        "y_train = sampled_train_df['diagnosis']\n",
        "y_val = val_df['diagnosis']\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPCJ13CxV5yO"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "data_generator = ImageDataGenerator(zoom_range=0.1, rotation_range=360, fill_mode='constant', cval=0.,\n",
        "                                    horizontal_flip=True, vertical_flip=True)\n",
        "data_generator = data_generator.flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdv8VK7-WPas"
      },
      "source": [
        "class Metrics(Callback):\n",
        "  def __init__(self, validation_data):\n",
        "    self.validation_data = validation_data\n",
        "\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_kappas = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    X_val, y_val = self.validation_data[:2]\n",
        "    \n",
        "    y_pred = self.model.predict(X_val)\n",
        "    y_pred = np.clip(y_pred,0,4)\n",
        "    y_pred = y_pred.astype(int)\n",
        "\n",
        "    _val_kappa = cohen_kappa_score(\n",
        "        y_val,\n",
        "        y_pred, \n",
        "        weights='quadratic'\n",
        "    )\n",
        "\n",
        "    self.val_kappas.append(_val_kappa)\n",
        "\n",
        "    print(f\"val_kappa: {_val_kappa:.4f}\")\n",
        "    \n",
        "    if _val_kappa == max(self.val_kappas):\n",
        "        print(\"Validation Kappa has improved. Saving model.\")\n",
        "        self.model.save('model.h5')\n",
        "\n",
        "    return\n",
        "    \n",
        "kappa_metrics = Metrics([x_val, y_val])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8PpQ1v0WR1y"
      },
      "source": [
        "mobilenet = MobileNetV2(\n",
        "    alpha = 1.3,\n",
        "    weights='mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.3_224_no_top.h5',\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(mobilenet)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer=Adam(lr=0.0001),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rWJJX57WThM"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    data_generator,\n",
        "    steps_per_epoch = x_train.shape[0] / BATCH_SIZE,\n",
        "    epochs = 100,\n",
        "    validation_data = (x_val, y_val),\n",
        "    callbacks = [kappa_metrics]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}